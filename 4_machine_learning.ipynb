{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c060b11a-6a02-4054-9075-6346654514ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "\n",
    "# Métricas de evaluación\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Para guardar el modelo\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f582e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/titanic_procesado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "589db77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.450565</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368146</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563505</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.615097</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483985</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.438286</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.546155</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.546155</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448347</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex       Age  SibSp  Parch      Fare  Embarked\n",
       "0     1.0  1.0  0.450565  0.125    0.0  0.368146       1.0\n",
       "1     0.0  0.0  0.563505  0.125    0.0  0.615097       0.0\n",
       "2     1.0  0.0  0.483985  0.000    0.0  0.438286       1.0\n",
       "3     0.0  0.0  0.546155  0.125    0.0  0.595112       1.0\n",
       "4     1.0  1.0  0.546155  0.000    0.0  0.448347       1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['Survived'], axis=1)\n",
    "y = df['Survived']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f340b431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46ba035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "X_train = X_train.values  # Convertir a NumPy array\n",
    "y_train = y_train.values  # Convertir a NumPy array\n",
    "X_test = X_test.values    # Convertir a NumPy array\n",
    "y_test = y_test.values    # Convertir a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8eb0da7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(),\n",
    "        'params': {\n",
    "            'model__C': [0.1],\n",
    "            'model__max_iter': [1000]\n",
    "        }\n",
    "    },\n",
    "    'Support Vector Classifier': {\n",
    "        'model': SVC(),\n",
    "        'params': {\n",
    "            'model__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "            'model__C': [0.1, 1, 10]\n",
    "        }\n",
    "    },\n",
    "    'Decision Tree Classifier': {\n",
    "        'model': DecisionTreeClassifier(),\n",
    "        'params': {\n",
    "            'model__splitter': ['best', 'random'],\n",
    "            'model__max_depth': [None, 1, 2, 3, 4]\n",
    "        }\n",
    "    },\n",
    "    'Random Forest Classifier': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'model__n_estimators': [10, 100],\n",
    "            'model__max_depth': [None, 1, 2, 3, 4],\n",
    "            'model__max_features': ['auto', 'sqrt', 'log2']\n",
    "        }\n",
    "    },\n",
    "    'Gradient Boosting Classifier': {\n",
    "        'model': GradientBoostingClassifier(),\n",
    "        'params': {\n",
    "            'model__n_estimators': [10, 100],\n",
    "            'model__max_depth': [None, 1, 2, 3, 4]\n",
    "        }\n",
    "    },\n",
    "    'AdaBoost Classifier': {\n",
    "        'model': AdaBoostClassifier(),\n",
    "        'params': {\n",
    "            'model__n_estimators': [10, 100]\n",
    "        }\n",
    "    },\n",
    "    'K-Nearest Neighbors Classifier': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'model__n_neighbors': [3, 5, 7]\n",
    "        }\n",
    "    },\n",
    "    'XGBoost Classifier': {\n",
    "        'model': XGBClassifier(),\n",
    "        'params': {\n",
    "            'model__n_estimators': [10, 100],\n",
    "            'model__max_depth': [None, 1, 2, 3]\n",
    "        }\n",
    "    },\n",
    "    'LGBM Classifier': {\n",
    "        'model': LGBMClassifier(),\n",
    "        'params': {\n",
    "            'model__n_estimators': [10, 100],\n",
    "            'model__max_depth': [None, 1, 2, 3],\n",
    "            'model__learning_rate': [0.1, 0.2, 0.3],\n",
    "            'model__verbose': [-1]\n",
    "        }\n",
    "    },\n",
    "    'GaussianNB': {\n",
    "        'model': GaussianNB(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'Naive Bayes Classifier': {\n",
    "        'model': BernoulliNB(),\n",
    "        'params': {\n",
    "            'model__alpha': [0.1, 1.0, 10.0]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8570ee26",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 300 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n300 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\CLIENTESS\\Desktop\\Borrar\\aprendizaje_supervisado\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 833, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\CLIENTESS\\Desktop\\Borrar\\aprendizaje_supervisado\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1336, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\CLIENTESS\\Desktop\\Borrar\\aprendizaje_supervisado\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1191, in fit\n    X, y = validate_data(\n           ~~~~~~~~~~~~~^\n        self,\n        ^^^^^\n    ...<5 lines>...\n        accept_large_sparse=solver not in [\"liblinear\", \"sag\", \"saga\"],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\CLIENTESS\\Desktop\\Borrar\\aprendizaje_supervisado\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2919, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\CLIENTESS\\Desktop\\Borrar\\aprendizaje_supervisado\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1314, in check_X_y\n    X = check_array(\n        X,\n    ...<12 lines>...\n        input_name=\"X\",\n    )\n  File \"c:\\Users\\CLIENTESS\\Desktop\\Borrar\\aprendizaje_supervisado\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1074, in check_array\n    _assert_all_finite(\n    ~~~~~~~~~~~~~~~~~~^\n        array,\n        ^^^^^^\n    ...<2 lines>...\n        allow_nan=ensure_all_finite == \"allow-nan\",\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\CLIENTESS\\Desktop\\Borrar\\aprendizaje_supervisado\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 133, in _assert_all_finite\n    _assert_all_finite_element_wise(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        X,\n        ^^\n    ...<4 lines>...\n        input_name=input_name,\n        ^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\CLIENTESS\\Desktop\\Borrar\\aprendizaje_supervisado\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 182, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 101\u001b[39m\n\u001b[32m     91\u001b[39m grid_search = GridSearchCV(\n\u001b[32m     92\u001b[39m     estimator=info_modelo[\u001b[33m'\u001b[39m\u001b[33mmodelo\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     93\u001b[39m     param_grid=info_modelo[\u001b[33m'\u001b[39m\u001b[33mparametros\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     97\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m,\n\u001b[32m     98\u001b[39m )\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# Ajustar GridSearchCV con los datos de entrenamiento\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# Hacer predicciones con el modelo ajustado\u001b[39;00m\n\u001b[32m    104\u001b[39m y_pred = grid_search.predict(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CLIENTESS\\Desktop\\Borrar\\aprendizaje_supervisado\\.venv\\Lib\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CLIENTESS\\Desktop\\Borrar\\aprendizaje_supervisado\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1053\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1047\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1048\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1049\u001b[39m     )\n\u001b[32m   1051\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1056\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1057\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CLIENTESS\\Desktop\\Borrar\\aprendizaje_supervisado\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1612\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1610\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1611\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1612\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CLIENTESS\\Desktop\\Borrar\\aprendizaje_supervisado\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1030\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) != n_candidates * n_splits:\n\u001b[32m   1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1025\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcv.split and cv.get_n_splits returned \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1026\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1027\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(n_splits, \u001b[38;5;28mlen\u001b[39m(out) // n_candidates)\n\u001b[32m   1028\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1030\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[32m   1033\u001b[39m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[32m   1034\u001b[39m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[32m   1035\u001b[39m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[32m   1036\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CLIENTESS\\Desktop\\Borrar\\aprendizaje_supervisado\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:479\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    473\u001b[39m     all_fits_failed_message = (\n\u001b[32m    474\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    475\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    476\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    477\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    478\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    482\u001b[39m     some_fits_failed_message = (\n\u001b[32m    483\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    484\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    489\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \nAll the 300 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n300 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\CLIENTESS\\Desktop\\Borrar\\aprendizaje_supervisado\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 833, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\CLIENTESS\\Desktop\\Borrar\\aprendizaje_supervisado\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1336, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\CLIENTESS\\Desktop\\Borrar\\aprendizaje_supervisado\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1191, in fit\n    X, y = validate_data(\n           ~~~~~~~~~~~~~^\n        self,\n        ^^^^^\n    ...<5 lines>...\n        accept_large_sparse=solver not in [\"liblinear\", \"sag\", \"saga\"],\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\CLIENTESS\\Desktop\\Borrar\\aprendizaje_supervisado\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2919, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\CLIENTESS\\Desktop\\Borrar\\aprendizaje_supervisado\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1314, in check_X_y\n    X = check_array(\n        X,\n    ...<12 lines>...\n        input_name=\"X\",\n    )\n  File \"c:\\Users\\CLIENTESS\\Desktop\\Borrar\\aprendizaje_supervisado\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1074, in check_array\n    _assert_all_finite(\n    ~~~~~~~~~~~~~~~~~~^\n        array,\n        ^^^^^^\n    ...<2 lines>...\n        allow_nan=ensure_all_finite == \"allow-nan\",\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\CLIENTESS\\Desktop\\Borrar\\aprendizaje_supervisado\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 133, in _assert_all_finite\n    _assert_all_finite_element_wise(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        X,\n        ^^\n    ...<4 lines>...\n        input_name=input_name,\n        ^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\CLIENTESS\\Desktop\\Borrar\\aprendizaje_supervisado\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 182, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    }
   ],
   "source": [
    "# Definir los modelos y sus respectivos hiperparámetros para GridSearch\n",
    "modelos = {\n",
    "    'Regresión Logística': {\n",
    "        'modelo': LogisticRegression(),\n",
    "        'parametros': {\n",
    "            'C': [0.01, 0.1, 1, 10, 100],\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'solver': ['liblinear', 'saga'],\n",
    "            'max_iter': [100, 500, 1000]\n",
    "        }\n",
    "    },\n",
    "    'Clasificador de Vectores de Soporte': {\n",
    "        'modelo': SVC(),\n",
    "        'parametros': {\n",
    "            'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "            'C': [0.1, 1, 10]\n",
    "        }\n",
    "    },\n",
    "    'Clasificador de Árbol de Decisión': {\n",
    "        'modelo': DecisionTreeClassifier(),\n",
    "        'parametros': {\n",
    "            'splitter': ['best', 'random'],\n",
    "            'max_depth': [None, 1, 2, 3, 4]\n",
    "        }\n",
    "    },\n",
    "    'Clasificador de Bosques Aleatorios': {\n",
    "        'modelo': RandomForestClassifier(),\n",
    "        'parametros': {\n",
    "            'n_estimators': [10, 100],\n",
    "            'max_depth': [None, 1, 2, 3, 4],\n",
    "            'max_features': ['sqrt', 'log2', None]\n",
    "        }\n",
    "    },\n",
    "    'Clasificador de Gradient Boosting': {\n",
    "        'modelo': GradientBoostingClassifier(),\n",
    "        'parametros': {\n",
    "            'n_estimators': [10, 100],\n",
    "            'max_depth': [None, 1, 2, 3, 4]\n",
    "        }\n",
    "    },\n",
    "    'Clasificador AdaBoost': {\n",
    "        'modelo': AdaBoostClassifier(),\n",
    "        'parametros': {\n",
    "            'n_estimators': [10, 100]\n",
    "        }\n",
    "    },\n",
    "    'Clasificador K-Nearest Neighbors': {\n",
    "        'modelo': KNeighborsClassifier(),\n",
    "        'parametros': {\n",
    "            'n_neighbors': [3, 5, 7]\n",
    "        }\n",
    "    },\n",
    "    'Clasificador XGBoost': {\n",
    "        'modelo': XGBClassifier(),\n",
    "        'parametros': {\n",
    "            'n_estimators': [10, 100],\n",
    "            'max_depth': [None, 1, 2, 3]\n",
    "        }\n",
    "    },\n",
    "    'Clasificador LGBM': {\n",
    "        'modelo': LGBMClassifier(),\n",
    "        'parametros': {\n",
    "            'n_estimators': [10, 100],\n",
    "            'max_depth': [None, 1, 2, 3],\n",
    "            'learning_rate': [0.1, 0.2, 0.3],\n",
    "            'verbose': [-1]\n",
    "        }\n",
    "    },\n",
    "    'GaussianNB': {\n",
    "        'modelo': GaussianNB(),\n",
    "        'parametros': {}\n",
    "    },\n",
    "    'Clasificador Naive Bayes': {\n",
    "        'modelo': BernoulliNB(),\n",
    "        'parametros': {\n",
    "            'alpha': [0.1, 1.0, 10.0]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Inicializar variables para almacenar los puntajes de los modelos y el mejor estimador\n",
    "puntajes_modelos = []\n",
    "mejor_precision = 0\n",
    "mejor_estimador = None\n",
    "mejor_modelo = None\n",
    "estimadores = {}\n",
    "\n",
    "# Iterar sobre cada modelo y sus hiperparámetros\n",
    "for nombre, info_modelo in modelos.items():\n",
    "    # Inicializar GridSearchCV con el modelo y los hiperparámetros\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=info_modelo['modelo'],\n",
    "        param_grid=info_modelo['parametros'],\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        verbose=0,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    # Ajustar GridSearchCV con los datos de entrenamiento\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Hacer predicciones con el modelo ajustado\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    \n",
    "    # Calcular la precisión de las predicciones\n",
    "    precision = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Almacenar los resultados del modelo\n",
    "    puntajes_modelos.append({\n",
    "        'Modelo': nombre,\n",
    "        'Precisión': precision\n",
    "    })\n",
    "\n",
    "    estimadores[nombre] = grid_search.best_estimator_\n",
    "    \n",
    "    # Actualizar el mejor modelo si la precisión actual es mayor que la mejor precisión encontrada\n",
    "    if precision > mejor_precision:\n",
    "        mejor_modelo = nombre\n",
    "        mejor_precision = precision\n",
    "        mejor_estimador = grid_search.best_estimator_\n",
    "\n",
    "# Convertir los resultados a un DataFrame para una mejor visualización\n",
    "metricas = pd.DataFrame(puntajes_modelos).sort_values('Precisión', ascending=False)\n",
    "\n",
    "# Imprimir el rendimiento de los modelos de clasificación\n",
    "print(\"Rendimiento de los modelos de clasificación\")\n",
    "print(metricas.round(2))\n",
    "\n",
    "# Imprimir el mejor modelo y su precisión\n",
    "print('---------------------------------------------------')\n",
    "print(\"MEJOR MODELO DE CLASIFICACIÓN\")\n",
    "print(f\"Modelo: {mejor_modelo}\")\n",
    "print(f\"Precisión: {mejor_precision:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705b54e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
